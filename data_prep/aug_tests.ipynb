{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd69ecdf-27c6-4240-961c-523c4f92049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc import PreProcessor\n",
    "from bert_model import Model\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as naf\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "pp = PreProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6dfdbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e36ea-a619-4476-85f9-9cf6c0b27a96",
   "metadata": {},
   "source": [
    "## Random Word Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161c6f2-035d-499c-bdf0-be5ebe43bd81",
   "metadata": {},
   "source": [
    "### 1. crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8435fd23-0f6d-4e44-b16d-bb9e2d7ce50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n",
      "    Iteration 1\n",
      "    Iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58174f7a3128448abe90052341fddd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399fc7e9f270434d8dd38849568331a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3610' max='3610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3610/3610 04:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.421251</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.350797</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.435331</td>\n",
       "      <td>0.584746</td>\n",
       "      <td>0.346734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.411613</td>\n",
       "      <td>0.920248</td>\n",
       "      <td>0.504451</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>0.427136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.534192</td>\n",
       "      <td>0.925024</td>\n",
       "      <td>0.464164</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.341709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>0.924546</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.371859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug(action=\"crop\")\n",
    "random_word_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = random_word_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\", num_train_epochs=5, layers_to_freeze=10)\n",
    "all_proc_model.to(device)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f55221-0862-4062-8a04-93e966478de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfefeb221d24445af1bfb9ac74c09cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0008781484211795032,\n",
       " 'eval_accuracy': 0.9998268548177647,\n",
       " 'eval_f1': 0.9997481108312343,\n",
       " 'eval_precision': 0.9997481108312343,\n",
       " 'eval_recall': 0.9997481108312343,\n",
       " 'eval_runtime': 10.2181,\n",
       " 'eval_samples_per_second': 1130.446,\n",
       " 'eval_steps_per_second': 17.714,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1907b7a7-63ad-4cf1-8956-ec62026a6da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.620749831199646,\n",
       " 'eval_accuracy': 0.9245463228271251,\n",
       " 'eval_f1': 0.48366013071895425,\n",
       " 'eval_precision': 0.6915887850467289,\n",
       " 'eval_recall': 0.37185929648241206,\n",
       " 'eval_runtime': 1.867,\n",
       " 'eval_samples_per_second': 1121.585,\n",
       " 'eval_steps_per_second': 17.675,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd58860-c28d-411d-a736-f65e598d0ee0",
   "metadata": {},
   "source": [
    "### 2. Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f60ab6-5a11-458e-9fd7-64ab56b71e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n",
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29526c301b064351878f1f2cca9fda3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5781c51fe1544867ac50b6be8e74b8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='722' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [722/722 00:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.914995</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.281407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug(action=\"swap\")\n",
    "random_word_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = random_word_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\")\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6975f-d691-4a5a-b321-63f7c11ccff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0387fce88314467790fefe4daaa32f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17353923618793488,\n",
       " 'eval_accuracy': 0.9498744697428794,\n",
       " 'eval_f1': 0.9236852510873863,\n",
       " 'eval_precision': 0.9687586397567044,\n",
       " 'eval_recall': 0.8826196473551637,\n",
       " 'eval_runtime': 10.2027,\n",
       " 'eval_samples_per_second': 1132.15,\n",
       " 'eval_steps_per_second': 17.74,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20090eab-29a4-4a07-aa0f-0bcd1d60ee3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2988002896308899,\n",
       " 'eval_accuracy': 0.9149952244508118,\n",
       " 'eval_f1': 0.38620689655172413,\n",
       " 'eval_precision': 0.6153846153846154,\n",
       " 'eval_recall': 0.2814070351758794,\n",
       " 'eval_runtime': 1.8797,\n",
       " 'eval_samples_per_second': 1114.014,\n",
       " 'eval_steps_per_second': 17.556,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52d4a9-6640-4e42-b366-693e7a2dae8b",
   "metadata": {},
   "source": [
    "## Synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13ee12-98aa-4f1c-9591-5daf3116671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /homes/yz10519/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /homes/yz10519/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /homes/yz10519/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2868ee5a30f2414f8cf4afb71658e416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdafb7e1cb3141f1bcb9f418f22f707b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='722' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [722/722 00:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.276340</td>\n",
       "      <td>0.907354</td>\n",
       "      <td>0.316901</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.226131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "synonym_word_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = synonym_word_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\")\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd94f6-4a1e-457b-9393-4e57c8074559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be988ca9bff843debf01d67a5a7a1a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14474880695343018,\n",
       " 'eval_accuracy': 0.9533373733875855,\n",
       " 'eval_f1': 0.9286754002911208,\n",
       " 'eval_precision': 0.9782548090326177,\n",
       " 'eval_recall': 0.8838790931989925,\n",
       " 'eval_runtime': 10.2465,\n",
       " 'eval_samples_per_second': 1127.313,\n",
       " 'eval_steps_per_second': 17.665,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2921728-14b2-4648-82ff-d0967e1e24bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27633965015411377,\n",
       " 'eval_accuracy': 0.9073543457497613,\n",
       " 'eval_f1': 0.31690140845070425,\n",
       " 'eval_precision': 0.5294117647058824,\n",
       " 'eval_recall': 0.22613065326633167,\n",
       " 'eval_runtime': 1.8861,\n",
       " 'eval_samples_per_second': 1110.234,\n",
       " 'eval_steps_per_second': 17.497,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0055c-d4ba-4b12-a4ee-a9c595d28203",
   "metadata": {},
   "source": [
    "## Contextual Word Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c276ed-ddb4-46c8-82d7-2857ad425f7f",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d905e83-9ef3-436d-96a1-52bdd1d56078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'torch.device' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m aug \u001b[38;5;241m=\u001b[39m naw\u001b[38;5;241m.\u001b[39mContextualWordEmbsAug(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsert\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m context_word_aug_train \u001b[38;5;241m=\u001b[39m pp\u001b[38;5;241m.\u001b[39maug_and_rebal(aug)\n\u001b[1;32m      3\u001b[0m pp\u001b[38;5;241m.\u001b[39maugmented \u001b[38;5;241m=\u001b[39m context_word_aug_train[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      4\u001b[0m all_proc_train \u001b[38;5;241m=\u001b[39m pp\u001b[38;5;241m.\u001b[39mrun_preprocess(white_func\u001b[38;5;241m=\u001b[39mpp\u001b[38;5;241m.\u001b[39mwhitespace_norm, punc_func\u001b[38;5;241m=\u001b[39mpp\u001b[38;5;241m.\u001b[39mremove_punc, dig_func\u001b[38;5;241m=\u001b[39mpp\u001b[38;5;241m.\u001b[39mremove_digits)\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/NLP_CW/preproc.py:118\u001b[0m, in \u001b[0;36mPreProcessor.aug_and_rebal\u001b[0;34m(self, aug)\u001b[0m\n\u001b[1;32m    114\u001b[0m df_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_train[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(\n\u001b[1;32m    115\u001b[0m     deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m texts \u001b[38;5;241m=\u001b[39m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 118\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m [aug\u001b[38;5;241m.\u001b[39maugment(text)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m    119\u001b[0m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m augmented_text\n\u001b[1;32m    120\u001b[0m all_data\u001b[38;5;241m.\u001b[39mappend(df_new)\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/NLP_CW/preproc.py:118\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m df_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_train[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(\n\u001b[1;32m    115\u001b[0m     deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m texts \u001b[38;5;241m=\u001b[39m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 118\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m [aug\u001b[38;5;241m.\u001b[39maugment(text)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m    119\u001b[0m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m augmented_text\n\u001b[1;32m    120\u001b[0m all_data\u001b[38;5;241m.\u001b[39mappend(df_new)\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/nlpaug/base_augmenter.py:98\u001b[0m, in \u001b[0;36mAugmenter.augment\u001b[0;34m(self, data, n, num_thread)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbstSummAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackTranslationAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContextualWordEmbsAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContextualWordEmbsForSentenceAug\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aug_num):\n\u001b[0;32m---> 98\u001b[0m         result \u001b[38;5;241m=\u001b[39m action_fx(clean_data)\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    100\u001b[0m             augmented_results\u001b[38;5;241m.\u001b[39mextend(result)\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/nlpaug/augmenter/word/context_word_embs.py:306\u001b[0m, in \u001b[0;36mContextualWordEmbsAug.insert\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masked_texts):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(masked_texts, target_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Update doc\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aug_input_pos, output, masked_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(aug_input_poses, outputs, masked_texts):\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/nlpaug/model/lang_models/bert.py:113\u001b[0m, in \u001b[0;36mBert.predict\u001b[0;34m(self, texts, target_words, n)\u001b[0m\n\u001b[1;32m    111\u001b[0m seed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_p}\n\u001b[1;32m    112\u001b[0m target_token_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_randomness(target_token_logits, seed)\n\u001b[0;32m--> 113\u001b[0m target_token_logits, target_token_idxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiltering(target_token_logits, seed)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target_token_idxes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    115\u001b[0m     new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpick(target_token_logits, target_token_idxes, target_word\u001b[38;5;241m=\u001b[39mtarget_token, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/nlpaug/model/lang_models/language_models.py:144\u001b[0m, in \u001b[0;36mLanguageModels.filtering\u001b[0;34m(self, logits, seed)\u001b[0m\n\u001b[1;32m    142\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, idxes)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# TODO: Externalize to util for checking\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m    145\u001b[0m     idxes \u001b[38;5;241m=\u001b[39m idxes\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    146\u001b[0m idxes \u001b[38;5;241m=\u001b[39m idxes\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'torch.device' is not iterable"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
    "context_word_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = context_word_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\", num_train_epochs=5, layers_to_freeze=10)\n",
    "all_proc_model.to(device)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f36804-21af-43b5-8ad3-cc52a2df7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb378621-90c3-4563-8a5d-4d021694202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27412e-5a99-4e35-a9dc-b808faf0c25e",
   "metadata": {},
   "source": [
    "### Substitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53c02a47-ff9a-471d-b7c0-3a68f6f43f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n",
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf1354822984f31a41890dd12e86c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c80d791c9d144168e6a8c32e0cdc584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='722' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [722/722 00:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>0.236915</td>\n",
       "      <td>0.918338</td>\n",
       "      <td>0.391459</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.276382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"substitute\")\n",
    "context_word_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = context_word_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\")\n",
    "all_proc_model.to(device)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ba052b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6601b2600cf848e4a9b8b33a4d66a2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211835768fb84ce386ef345e162c3ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1444' max='1444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1444/1444 01:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.369774</td>\n",
       "      <td>0.879179</td>\n",
       "      <td>0.306849</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.281407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.227712</td>\n",
       "      <td>0.920726</td>\n",
       "      <td>0.496970</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "all_proc_model = Model(\"baseline\", num_train_epochs=2, layers_to_freeze=10)\n",
    "all_proc_model.to(device)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "775751e2-9bc8-4651-a0aa-8ab00e24ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98546cbe52b4078a21d9b805bcf5db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10596803575754166,\n",
       " 'eval_accuracy': 0.9665829798285863,\n",
       " 'eval_f1': 0.9506267587618317,\n",
       " 'eval_precision': 0.9656964656964657,\n",
       " 'eval_recall': 0.9360201511335012,\n",
       " 'eval_runtime': 10.1672,\n",
       " 'eval_samples_per_second': 1136.1,\n",
       " 'eval_steps_per_second': 17.802,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f98f2c9b-edfc-4b83-b8bd-a8cfbd485de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22771206498146057,\n",
       " 'eval_accuracy': 0.9207258834765998,\n",
       " 'eval_f1': 0.49696969696969695,\n",
       " 'eval_precision': 0.6259541984732825,\n",
       " 'eval_recall': 0.4120603015075377,\n",
       " 'eval_runtime': 1.8672,\n",
       " 'eval_samples_per_second': 1121.483,\n",
       " 'eval_steps_per_second': 17.674,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5fda6-7fb4-420a-a689-1bb7d11f46e0",
   "metadata": {},
   "source": [
    "## Sentence Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "444466d4-fc65-49f7-8624-a60b63dab18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabd6adee2654c6092771fa325773895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09443b1b562b4b2fafc514a25a914829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2166' max='2166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2166/2166 02:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.454750</td>\n",
       "      <td>0.916905</td>\n",
       "      <td>0.350746</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.236181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.275619</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.542199</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.532663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.926457</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.671756</td>\n",
       "      <td>0.442211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', device='cuda')\n",
    "sentence_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = sentence_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\", num_train_epochs=3, layers_to_freeze=10)\n",
    "all_proc_model.to(device)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdadbd27-edba-44bd-b5c0-f7a7b2102f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d1ca5cc81d4d7d8963b9d2f4f184a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.034351758658885956,\n",
       " 'eval_accuracy': 0.9925547571638819,\n",
       " 'eval_f1': 0.9891084093211753,\n",
       " 'eval_precision': 0.9946510443199185,\n",
       " 'eval_recall': 0.9836272040302267,\n",
       " 'eval_runtime': 10.3022,\n",
       " 'eval_samples_per_second': 1121.222,\n",
       " 'eval_steps_per_second': 17.569,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f3c3016-1cdf-4564-b12c-950fc505bc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.38056284189224243,\n",
       " 'eval_accuracy': 0.9264565425023877,\n",
       " 'eval_f1': 0.5333333333333333,\n",
       " 'eval_precision': 0.6717557251908397,\n",
       " 'eval_recall': 0.44221105527638194,\n",
       " 'eval_runtime': 1.8911,\n",
       " 'eval_samples_per_second': 1107.275,\n",
       " 'eval_steps_per_second': 17.45,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2333ba8-e308-4c71-b9e3-d09e9f0c711d",
   "metadata": {},
   "source": [
    "## Back translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97352bab-7ec8-4294-b942-893cddd057f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n",
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca1d6e787074c5eb79b849a33f0519b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b153fd792eb74ed09987a5eedc069939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='722' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [722/722 00:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.229715</td>\n",
       "      <td>0.916905</td>\n",
       "      <td>0.502857</td>\n",
       "      <td>0.582781</td>\n",
       "      <td>0.442211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "aug = naw.BackTranslationAug(device='cuda')\n",
    "backtranslate_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = backtranslate_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\")\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f664df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492fe2d5624e42b9a6b7164706f6d367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649e115e21a04f898fa3baf6e37c4aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3610' max='3610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3610/3610 04:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.450151</td>\n",
       "      <td>0.830946</td>\n",
       "      <td>0.432692</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.678392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.304329</td>\n",
       "      <td>0.896371</td>\n",
       "      <td>0.541226</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.643216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.432958</td>\n",
       "      <td>0.905922</td>\n",
       "      <td>0.538642</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.577889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>0.915950</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.457286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.591571</td>\n",
       "      <td>0.922159</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.422111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "all_proc_model = Model(\"baseline\", num_train_epochs=5, layers_to_freeze=6)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6531a29-3a70-4774-afee-d46cf5a0e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60152c2d27bb4523b1c32be4d7c440fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11783909797668457,\n",
       " 'eval_accuracy': 0.9593108821747035,\n",
       " 'eval_f1': 0.9393704850361198,\n",
       " 'eval_precision': 0.9627181385510312,\n",
       " 'eval_recall': 0.9171284634760706,\n",
       " 'eval_runtime': 10.0978,\n",
       " 'eval_samples_per_second': 1143.908,\n",
       " 'eval_steps_per_second': 17.925,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "all_proc_model.evaluate_train(all_proc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7af111d4-abb8-4102-820b-99ffbd33ab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/33 00:00 < 00:01, 17.63 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3612107038497925,\n",
       " 'eval_accuracy': 0.9307545367717287,\n",
       " 'eval_f1': 0.5938375350140056,\n",
       " 'eval_precision': 0.6708860759493671,\n",
       " 'eval_recall': 0.5326633165829145,\n",
       " 'eval_runtime': 1.8521,\n",
       " 'eval_samples_per_second': 1130.615,\n",
       " 'eval_steps_per_second': 17.818,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev metrics\n",
    "all_proc_model.evaluate_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93706a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation: rebalancing 4 times...\n",
      "    Iteration 0\n",
      "    Iteration 1\n",
      "    Iteration 2\n",
      "    Iteration 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'save_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1513212/879788802.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbacktranslate_aug_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_and_rebal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktranslate_aug_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mall_proc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_proc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mall_proc_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"augmented_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'save_csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "aug = naf.Sequential([\n",
    "    nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', device='cuda'),\n",
    "    naw.RandomWordAug(action=\"crop\")\n",
    "    naw.BackTranslationAug(device='cuda'),\n",
    "])\n",
    "    \n",
    "backtranslate_aug_train = pp.aug_and_rebal(aug)\n",
    "pp.augmented = backtranslate_aug_train[[\"text\",\"label\"]]\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "\n",
    "all_proc_train.to_csv(\"aug_datasets/gpt2_crop_bt.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de147f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proc_train.to_csv(\"aug_datasets/bt_gpt2_crop.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c179f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63941a3dc28456fb76e7bb56fdb2b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecd862c1cb745788ac94fdc7d208e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6406' max='7220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6406/7220 08:08 < 01:02, 13.10 it/s, Epoch 8.87/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.380652</td>\n",
       "      <td>0.889207</td>\n",
       "      <td>0.411168</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.407035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.231985</td>\n",
       "      <td>0.917861</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.341709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.763213</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.296912</td>\n",
       "      <td>0.628141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.582409</td>\n",
       "      <td>0.883954</td>\n",
       "      <td>0.468271</td>\n",
       "      <td>0.414729</td>\n",
       "      <td>0.537688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>0.888730</td>\n",
       "      <td>0.435835</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.452261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.680152</td>\n",
       "      <td>0.909742</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.376884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.016108</td>\n",
       "      <td>0.880611</td>\n",
       "      <td>0.434389</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.482412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.812210</td>\n",
       "      <td>0.905444</td>\n",
       "      <td>0.456044</td>\n",
       "      <td>0.503030</td>\n",
       "      <td>0.417085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1513212/1561502277.py\", line 4, in <module>\n",
      "    all_proc_model.train(all_proc_train, pp.raw_dev)\n",
      "  File \"/vol/bitbucket/yz10519/NLP_CW/bert_model.py\", line 111, in train\n",
      "    self.trainer.train()\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/transformers/trainer.py\", line 1624, in train\n",
      "    else:\n",
      "          \n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/transformers/trainer.py\", line 1928, in _inner_training_loop\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/accelerate/data_loader.py\", line 460, in __iter__\n",
      "    current_batch = send_to_device(current_batch, self.device)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 167, in send_to_device\n",
      "    {\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 168, in <dictcomp>\n",
      "    k: t if k in skip_keys else send_to_device(t, device, non_blocking=non_blocking, skip_keys=skip_keys)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 186, in send_to_device\n",
      "    return tensor.to(device, non_blocking=non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/vol/bitbucket/yz10519/miniconda3/envs/DLCW1/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "all_proc_train = pp.run_preprocess(white_func=pp.whitespace_norm, punc_func=pp.remove_punc, dig_func=pp.remove_digits)\n",
    "all_proc_train = all_proc_train[[\"text\",\"label\"]]\n",
    "all_proc_model = Model(\"baseline\", num_train_epochs=10, layers_to_freeze=10)\n",
    "all_proc_model.train(all_proc_train, pp.raw_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d2a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
